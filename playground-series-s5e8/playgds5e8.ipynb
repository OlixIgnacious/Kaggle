{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" =============== TRAIN ================\")\n",
    "print(train.info())\n",
    "print(train.isna().sum())\n",
    "print(\" ======================================\")\n",
    "print(\" =============== TEST ================\")\n",
    "print(test.info())\n",
    "print(test.isna().sum())\n",
    "print(\" ======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary categorical features mapping\n",
    "binary_map = {'yes' : 1, 'no' : 0}\n",
    "binary_columns = ['default', 'housing', 'loan']\n",
    "\n",
    "for col in binary_columns:\n",
    "    train[col] = train[col].map(binary_map)\n",
    "    test[col] = test[col].map(binary_map)\n",
    "\n",
    "# Ordinal encoding for date-related features\n",
    "month_order = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "\n",
    "ord_enc = OrdinalEncoder(categories=[month_order])\n",
    "train[['month']] = ord_enc.fit_transform(train[['month']]).astype(int)\n",
    "test[['month']] = ord_enc.fit_transform(test[['month']]).astype(int)\n",
    "\n",
    "\n",
    "# One-Hot encode categorical features (excluding already encoded ones)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['job', 'marital', 'education', 'contact', 'poutcome']\n",
    "\n",
    "# Fill missing values in categorical columns\n",
    "# train[categorical_cols] = train[categorical_cols].fillna(\"missing\")\n",
    "# test[categorical_cols] = test[categorical_cols].fillna(\"missing\")\n",
    "\n",
    "# Fit the encoder on train data only\n",
    "encoder = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "encoder.fit(train[categorical_cols])\n",
    "\n",
    "# Transform train and test data\n",
    "encoded_train = encoder.transform(train[categorical_cols])\n",
    "encoded_test = encoder.transform(test[categorical_cols])\n",
    "\n",
    "# Convert to DataFrame\n",
    "encoded_train_df = pd.DataFrame(encoded_train.toarray().astype(int), columns=encoder.get_feature_names_out(categorical_cols))\n",
    "encoded_test_df = pd.DataFrame(encoded_test.toarray().astype(int), columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Concatenate the encoded features with the original data\n",
    "train = pd.concat([train.reset_index(drop=True), encoded_train_df], axis=1).drop(columns=categorical_cols)\n",
    "test = pd.concat([test.reset_index(drop=True), encoded_test_df], axis=1).drop(columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the final dataframe structure\n",
    "print(\"DataFrame shape after encoding:\", train.shape)\n",
    "print(\"Sample data:\\n\", train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction features\n",
    "train['default_housing'] = train['default'] * train['housing']\n",
    "test['default_housing'] = test['default'] * test['housing']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclic encoding for month feature\n",
    "import numpy as np\n",
    "train['month_sin'] = train['month'].apply(lambda x: np.sin(2 * np.pi * x / 12))\n",
    "test['month_sin'] = test['month'].apply(lambda x: np.sin(2 * np.pi * x / 12))\n",
    "\n",
    "train['month_cos'] = train['month'].apply(lambda x: np.cos(2 * np.pi * x / 12))\n",
    "test['month_cos'] = test['month'].apply(lambda x: np.cos(2 * np.pi * x / 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation for balance feature\n",
    "\n",
    "train['balance_log'] = np.log1p(train['balance'])\n",
    "test['balance_log'] = np.log1p(test['balance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data\n",
    "X = train.drop(columns=['y'])  # Replace 'target' with your target column\n",
    "y = train['y']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a LightGBM model\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = lgb_model.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------- Models --------------------\n",
    "models = {\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('clf', LogisticRegression(max_iter=1000))\n",
    "    ]),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': LGBMClassifier(),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0)\n",
    "}\n",
    "\n",
    "# -------------------- Handle Missing Values --------------------\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Replace infinity values with NaN\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Impute missing values with the mean for numerical columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# -------------------- Cross-Validation --------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "# -------------------- Evaluation --------------------\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating: {name}\")\n",
    "    scores = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "    results[name] = {\n",
    "        'Accuracy': np.mean(scores['test_accuracy']),\n",
    "        'F1 Score': np.mean(scores['test_f1']),\n",
    "        'ROC AUC': np.mean(scores['test_roc_auc'])\n",
    "    }\n",
    "\n",
    "# -------------------- Display Results --------------------\n",
    "results_df = pd.DataFrame(results).T.sort_values(by=\"ROC AUC\", ascending=False)\n",
    "print(\"\\nModel Performance:\\n\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
